{
  "img2latex": {
    "creation_time": "2025-04-16 12:00:36",
    "last_updated": "2025-04-16 14:20:59",
    "metadata": {},
    "metrics": {
      "steps": {
        "1": {
          "epoch": 1,
          "step": 1177,
          "train_acc": 0.4874551073401711,
          "train_loss": 2.3702572399324375,
          "val_acc": 0.5356039383702728,
          "val_bleu": 0.10476534937472688,
          "val_levenshtein": 0.24407168494060164,
          "val_loss": 2.0509148696275026
        },
        "10": {
          "epoch": 10,
          "step": 11770,
          "train_acc": 0.5922930570769402,
          "train_loss": 1.7398175035652153,
          "val_acc": 0.6007291752492379,
          "val_bleu": 0.1409826807991773,
          "val_levenshtein": 0.27129777330863775,
          "val_loss": 1.697684685901929
        },
        "11": {
          "epoch": 11,
          "step": 12947,
          "train_acc": 0.5950756780038493,
          "train_loss": 1.7239406384633096,
          "val_acc": 0.6020515778198896,
          "val_bleu": 0.1411403115395104,
          "val_levenshtein": 0.27209093520122773,
          "val_loss": 1.684455459120738
        },
        "12": {
          "epoch": 12,
          "step": 14124,
          "train_acc": 0.5970722608065303,
          "train_loss": 1.7135911904154169,
          "val_acc": 0.6034501936228063,
          "val_bleu": 0.1453709532319887,
          "val_levenshtein": 0.27231085873582783,
          "val_loss": 1.6790409728475226
        },
        "13": {
          "epoch": 13,
          "step": 15301,
          "train_acc": 0.5985820515778911,
          "train_loss": 1.7038641224902003,
          "val_acc": 0.6030176320342754,
          "val_bleu": 0.14513611777609103,
          "val_levenshtein": 0.27322309580918386,
          "val_loss": 1.6744782597930343
        },
        "14": {
          "epoch": 14,
          "step": 16478,
          "train_acc": 0.6002764004234493,
          "train_loss": 1.6971575421552174,
          "val_acc": 0.6065666968773173,
          "val_bleu": 0.14558741400515068,
          "val_levenshtein": 0.2743267765207146,
          "val_loss": 1.6678592124720202
        },
        "15": {
          "epoch": 15,
          "step": 17655,
          "train_acc": 0.6017078172180962,
          "train_loss": 1.6879282553130233,
          "val_acc": 0.6086162148801186,
          "val_bleu": 0.14671101987134455,
          "val_levenshtein": 0.2749460379785246,
          "val_loss": 1.6529608988562507
        },
        "16": {
          "epoch": 16,
          "step": 18832,
          "train_acc": 0.6029792683593913,
          "train_loss": 1.6823123165572138,
          "val_acc": 0.600611765675208,
          "val_bleu": 0.14022111739264978,
          "val_levenshtein": 0.27095953345228063,
          "val_loss": 1.6982378872776829
        },
        "17": {
          "epoch": 17,
          "step": 20009,
          "train_acc": 0.6039048167588844,
          "train_loss": 1.6765247394253906,
          "val_acc": 0.6096852599489165,
          "val_bleu": 0.14827069272194277,
          "val_levenshtein": 0.27626570314039633,
          "val_loss": 1.6481268319605071
        },
        "18": {
          "epoch": 18,
          "step": 21186,
          "train_acc": 0.6050634185671399,
          "train_loss": 1.6703535628247523,
          "val_acc": 0.6100127708659471,
          "val_bleu": 0.14515394777595186,
          "val_levenshtein": 0.27588133065518233,
          "val_loss": 1.646366011968223
        },
        "19": {
          "epoch": 19,
          "step": 22363,
          "train_acc": 0.6063215392373223,
          "train_loss": 1.6640534861623866,
          "val_acc": 0.612006673807366,
          "val_bleu": 0.14641949852349503,
          "val_levenshtein": 0.2759396155841295,
          "val_loss": 1.6353493583387513
        },
        "2": {
          "epoch": 2,
          "step": 2354,
          "train_acc": 0.5430670747935961,
          "train_loss": 2.013614749252816,
          "val_acc": 0.5577778693252039,
          "val_bleu": 0.11292330564900274,
          "val_levenshtein": 0.2517158897718798,
          "val_loss": 1.921938541941033
        },
        "20": {
          "epoch": 20,
          "step": 23540,
          "train_acc": 0.60685039120336,
          "train_loss": 1.6620076141971878,
          "val_acc": 0.611913982038395,
          "val_bleu": 0.14744443713224906,
          "val_levenshtein": 0.27623145501752655,
          "val_loss": 1.6315797140948662
        },
        "21": {
          "epoch": 21,
          "step": 24717,
          "train_acc": 0.6080503634392064,
          "train_loss": 1.6554664863981072,
          "val_acc": 0.6126802339952212,
          "val_bleu": 0.14991503323692817,
          "val_levenshtein": 0.2769630285146091,
          "val_loss": 1.629608402030015
        },
        "22": {
          "epoch": 22,
          "step": 25894,
          "train_acc": 0.6086626457675525,
          "train_loss": 1.652249168839735,
          "val_acc": 0.6132590425970174,
          "val_bleu": 0.14808033853497998,
          "val_levenshtein": 0.2767836251267639,
          "val_loss": 1.6247329583162333
        },
        "23": {
          "epoch": 23,
          "step": 27071,
          "train_acc": 0.608931093875476,
          "train_loss": 1.6507872178854637,
          "val_acc": 0.6128450193622806,
          "val_bleu": 0.14767677665647466,
          "val_levenshtein": 0.27764584441362045,
          "val_loss": 1.6321298648237186
        },
        "24": {
          "epoch": 24,
          "step": 28248,
          "train_acc": 0.6100848691338457,
          "train_loss": 1.6449554047525938,
          "val_acc": 0.6136936640026366,
          "val_bleu": 0.14749958487087397,
          "val_levenshtein": 0.2765634134941857,
          "val_loss": 1.621716092080056
        },
        "25": {
          "epoch": 25,
          "step": 29425,
          "train_acc": 0.6105723506722924,
          "train_loss": 1.6424175710845967,
          "val_acc": 0.6152694240751422,
          "val_bleu": 0.1493327714981591,
          "val_levenshtein": 0.27688807538303706,
          "val_loss": 1.61288163738866
        },
        "26": {
          "epoch": 26,
          "step": 30602,
          "train_acc": 0.6114271096734633,
          "train_loss": 1.6380962672688089,
          "val_acc": 0.6169543544533246,
          "val_bleu": 0.1505597640080693,
          "val_levenshtein": 0.2790997563059635,
          "val_loss": 1.609881739120757
        },
        "27": {
          "epoch": 27,
          "step": 31779,
          "train_acc": 0.6119996304241802,
          "train_loss": 1.6358401567300107,
          "val_acc": 0.616754552195765,
          "val_bleu": 0.14836413930313797,
          "val_levenshtein": 0.2774058552599548,
          "val_loss": 1.6105768872275859
        },
        "3": {
          "epoch": 3,
          "step": 3531,
          "train_acc": 0.560416682946696,
          "train_loss": 1.9161594687787769,
          "val_acc": 0.5727239021174919,
          "val_bleu": 0.12463802937941197,
          "val_levenshtein": 0.26001483905699196,
          "val_loss": 1.8526617032795112
        },
        "4": {
          "epoch": 4,
          "step": 4708,
          "train_acc": 0.5698325922663962,
          "train_loss": 1.863844784493068,
          "val_acc": 0.5813071599241987,
          "val_bleu": 0.12996033127305828,
          "val_levenshtein": 0.2632644162581882,
          "val_loss": 1.8042723741725069
        },
        "5": {
          "epoch": 5,
          "step": 5885,
          "train_acc": 0.5771852664278521,
          "train_loss": 1.8232575632321482,
          "val_acc": 0.5870231523440719,
          "val_bleu": 0.13299778250260688,
          "val_levenshtein": 0.2652386800570421,
          "val_loss": 1.7731583476778712
        },
        "6": {
          "epoch": 6,
          "step": 7062,
          "train_acc": 0.5818706971882359,
          "train_loss": 1.7978105680841974,
          "val_acc": 0.5916515613413529,
          "val_bleu": 0.13712239802046855,
          "val_levenshtein": 0.26727106008328677,
          "val_loss": 1.7464637444153197
        },
        "7": {
          "epoch": 7,
          "step": 8239,
          "train_acc": 0.5855345082228322,
          "train_loss": 1.7769536069064233,
          "val_acc": 0.5905763368212903,
          "val_bleu": 0.13384395367803373,
          "val_levenshtein": 0.26588232532770223,
          "val_loss": 1.7423482852170118
        },
        "8": {
          "epoch": 8,
          "step": 9416,
          "train_acc": 0.5887420953753838,
          "train_loss": 1.7595323736031798,
          "val_acc": 0.5976456290681388,
          "val_bleu": 0.1419006629023416,
          "val_levenshtein": 0.26967471358013306,
          "val_loss": 1.7093058798617928
        },
        "9": {
          "epoch": 9,
          "step": 10593,
          "train_acc": 0.5906991464361445,
          "train_loss": 1.7481376844020984,
          "val_acc": 0.594786602949658,
          "val_bleu": 0.1393150290466156,
          "val_levenshtein": 0.26955659205131416,
          "val_loss": 1.7243045365084029
        }
      }
    },
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v1",
    "status": "training"
  },
  "img2latex_v1": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v1/config.yaml",
    "creation_time": "2025-04-16 12:00:37",
    "description": "Image-to-LaTeX model: cnn_lstm with 512 embedding dim, 512 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=100",
    "last_updated": "2025-04-16 12:00:37",
    "metrics": {},
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v1",
    "status": "created",
    "tags": [
      "cnn_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v2": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v2/config.yaml",
    "creation_time": "2025-04-16 15:20:40",
    "description": "Image-to-LaTeX model: cnn_lstm with 256 embedding dim, 256 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=100",
    "last_updated": "2025-04-16 16:52:58",
    "metrics": {
      "steps": {
        "1": {
          "epoch": 1,
          "step": 295,
          "train_acc": 0.4345669228721925,
          "train_loss": 2.7401111927051476,
          "val_acc": 0.49856018785531847,
          "val_bleu": 0.08272097311416297,
          "val_levenshtein": 0.23108864871933585,
          "val_loss": 2.2777663411490234
        },
        "10": {
          "epoch": 10,
          "step": 2950,
          "train_acc": 0.5974997552249701,
          "train_loss": 1.7158550676100677,
          "val_acc": 0.6021916453818901,
          "val_bleu": 0.13768435021346004,
          "val_levenshtein": 0.27159857983135866,
          "val_loss": 1.690942862697542
        },
        "11": {
          "epoch": 11,
          "step": 3245,
          "train_acc": 0.6010500274194001,
          "train_loss": 1.6966468894271824,
          "val_acc": 0.602708659471039,
          "val_bleu": 0.14100513682204877,
          "val_levenshtein": 0.2731538166329558,
          "val_loss": 1.68396279304828
        },
        "12": {
          "epoch": 12,
          "step": 3540,
          "train_acc": 0.6052551015483112,
          "train_loss": 1.6727694689019974,
          "val_acc": 0.605800444920491,
          "val_bleu": 0.14316423415286322,
          "val_levenshtein": 0.27533078645510806,
          "val_loss": 1.671622101465861
        },
        "13": {
          "epoch": 13,
          "step": 3835,
          "train_acc": 0.6081510314796778,
          "train_loss": 1.6560163359735465,
          "val_acc": 0.6069065666968774,
          "val_bleu": 0.14273913646112804,
          "val_levenshtein": 0.2743617898133541,
          "val_loss": 1.6619694687274764
        },
        "14": {
          "epoch": 14,
          "step": 4130,
          "train_acc": 0.6112568014132138,
          "train_loss": 1.6396521395078651,
          "val_acc": 0.6087810002471781,
          "val_bleu": 0.14611443044256386,
          "val_levenshtein": 0.2768257189489744,
          "val_loss": 1.65096236522907
        },
        "15": {
          "epoch": 15,
          "step": 4425,
          "train_acc": 0.6141297477736964,
          "train_loss": 1.623559348507998,
          "val_acc": 0.611574112218835,
          "val_bleu": 0.14642940600003185,
          "val_levenshtein": 0.2780532854900395,
          "val_loss": 1.6338028678757315
        },
        "16": {
          "epoch": 16,
          "step": 4720,
          "train_acc": 0.615846390683012,
          "train_loss": 1.6123432828183588,
          "val_acc": 0.6156298920655846,
          "val_bleu": 0.14773960579528844,
          "val_levenshtein": 0.2785027797051637,
          "val_loss": 1.6171628913856606
        },
        "17": {
          "epoch": 17,
          "step": 5015,
          "train_acc": 0.6188278194980664,
          "train_loss": 1.5961833279966635,
          "val_acc": 0.616414682376205,
          "val_bleu": 0.14917275225780782,
          "val_levenshtein": 0.27993925468224173,
          "val_loss": 1.615428679476502
        },
        "18": {
          "epoch": 18,
          "step": 5310,
          "train_acc": 0.6208745064852742,
          "train_loss": 1.5855409518146546,
          "val_acc": 0.6164455796325287,
          "val_bleu": 0.14911162710805476,
          "val_levenshtein": 0.2797929659956936,
          "val_loss": 1.6135660497375999
        },
        "19": {
          "epoch": 19,
          "step": 5605,
          "train_acc": 0.6231521783598648,
          "train_loss": 1.5735839391190203,
          "val_acc": 0.6189194199555079,
          "val_bleu": 0.15035389127093077,
          "val_levenshtein": 0.28048010351798003,
          "val_loss": 1.6041016831620192
        },
        "2": {
          "epoch": 2,
          "step": 590,
          "train_acc": 0.5130797203542964,
          "train_loss": 2.1966869467067305,
          "val_acc": 0.5333628573782648,
          "val_bleu": 0.09897762361396209,
          "val_levenshtein": 0.24416079033255994,
          "val_loss": 2.067960963140964
        },
        "20": {
          "epoch": 20,
          "step": 5900,
          "train_acc": 0.6247801046855687,
          "train_loss": 1.5655826694519566,
          "val_acc": 0.6179780835461811,
          "val_bleu": 0.15024613900458966,
          "val_levenshtein": 0.2799136661217267,
          "val_loss": 1.6029840972403615
        },
        "21": {
          "epoch": 21,
          "step": 6195,
          "train_acc": 0.6271138564731159,
          "train_loss": 1.5530937756655898,
          "val_acc": 0.6206702644805141,
          "val_bleu": 0.1506833474365959,
          "val_levenshtein": 0.280528384434643,
          "val_loss": 1.5934206161020477
        },
        "22": {
          "epoch": 22,
          "step": 6490,
          "train_acc": 0.628281421874016,
          "train_loss": 1.546151497152627,
          "val_acc": 0.620414847161572,
          "val_bleu": 0.15021147324688597,
          "val_levenshtein": 0.27995006820296614,
          "val_loss": 1.590993117118252
        },
        "23": {
          "epoch": 23,
          "step": 6785,
          "train_acc": 0.6289633444221402,
          "train_loss": 1.5432109546344648,
          "val_acc": 0.6233706846832001,
          "val_bleu": 0.15428465078783227,
          "val_levenshtein": 0.28235757205715767,
          "val_loss": 1.5823748853186694
        },
        "24": {
          "epoch": 24,
          "step": 7080,
          "train_acc": 0.6313285837017982,
          "train_loss": 1.5309759527518083,
          "val_acc": 0.621339705034193,
          "val_bleu": 0.1521877016263084,
          "val_levenshtein": 0.28286879230407597,
          "val_loss": 1.5865300540286011
        },
        "25": {
          "epoch": 25,
          "step": 7375,
          "train_acc": 0.6328992809360013,
          "train_loss": 1.522617066502769,
          "val_acc": 0.6255685095163549,
          "val_bleu": 0.15393069367470974,
          "val_levenshtein": 0.2822745677889983,
          "val_loss": 1.566342231933931
        },
        "26": {
          "epoch": 26,
          "step": 7670,
          "train_acc": 0.6346423549518333,
          "train_loss": 1.5144211871582025,
          "val_acc": 0.6251792040866772,
          "val_bleu": 0.15333156036251572,
          "val_levenshtein": 0.28264480437180517,
          "val_loss": 1.569145346314534
        },
        "3": {
          "epoch": 3,
          "step": 885,
          "train_acc": 0.5391614765933016,
          "train_loss": 2.043441738903384,
          "val_acc": 0.5535387657576007,
          "val_bleu": 0.11167372409544399,
          "val_levenshtein": 0.2523765644902972,
          "val_loss": 1.9548319071709326
        },
        "4": {
          "epoch": 4,
          "step": 1180,
          "train_acc": 0.5550017536464584,
          "train_loss": 1.952216782245237,
          "val_acc": 0.5684497816593886,
          "val_bleu": 0.12170668873013338,
          "val_levenshtein": 0.2584241674267468,
          "val_loss": 1.8801057896164013
        },
        "5": {
          "epoch": 5,
          "step": 1475,
          "train_acc": 0.5660106542641189,
          "train_loss": 1.8907970258414408,
          "val_acc": 0.5759742934827388,
          "val_bleu": 0.12406481733351704,
          "val_levenshtein": 0.26092491474963847,
          "val_loss": 1.8408124612081294
        },
        "6": {
          "epoch": 6,
          "step": 1770,
          "train_acc": 0.5750939913131295,
          "train_loss": 1.8418854286883686,
          "val_acc": 0.5827634506055862,
          "val_bleu": 0.13082221719578727,
          "val_levenshtein": 0.2645082903757396,
          "val_loss": 1.7983143315947612
        },
        "7": {
          "epoch": 7,
          "step": 2065,
          "train_acc": 0.5823186469847623,
          "train_loss": 1.8016088558027255,
          "val_acc": 0.5891509433962264,
          "val_bleu": 0.13138759462922261,
          "val_levenshtein": 0.26572794417971873,
          "val_loss": 1.763406625984675
        },
        "8": {
          "epoch": 8,
          "step": 2360,
          "train_acc": 0.5873511296654925,
          "train_loss": 1.7727904217221815,
          "val_acc": 0.5880139243635165,
          "val_bleu": 0.1325431451209118,
          "val_levenshtein": 0.26707209235848156,
          "val_loss": 1.7557119517628295
        },
        "9": {
          "epoch": 9,
          "step": 2655,
          "train_acc": 0.5929425727901182,
          "train_loss": 1.7414959232722433,
          "val_acc": 0.5968402405866359,
          "val_bleu": 0.13766686484958082,
          "val_levenshtein": 0.2698004634830798,
          "val_loss": 1.7187264881680944
        }
      }
    },
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v2",
    "status": "training",
    "tags": [
      "cnn_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v3": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v3/config.yaml",
    "creation_time": "2025-04-16 18:21:12",
    "description": "Image-to-LaTeX model: resnet_lstm with 256 embedding dim, 256 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=100",
    "last_updated": "2025-04-16 20:21:28",
    "metrics": {
      "steps": {
        "1": {
          "epoch": 1,
          "step": 295,
          "train_acc": 0.4107410041154382,
          "train_loss": 2.870685489091395,
          "val_acc": 0.4817809178544945,
          "val_bleu": 0.06943355880113808,
          "val_levenshtein": 0.2209771490648104,
          "val_loss": 2.380616854197093
        },
        "10": {
          "epoch": 10,
          "step": 2950,
          "train_acc": 0.5556579345951926,
          "train_loss": 1.90874498853807,
          "val_acc": 0.561913982038395,
          "val_bleu": 0.11986940421345701,
          "val_levenshtein": 0.25480744854148596,
          "val_loss": 1.8751783284377597
        },
        "11": {
          "epoch": 11,
          "step": 3245,
          "train_acc": 0.5576818678472254,
          "train_loss": 1.8964156132605892,
          "val_acc": 0.5618789651478948,
          "val_bleu": 0.12319319314651475,
          "val_levenshtein": 0.25845842563562454,
          "val_loss": 1.8746249346180486
        },
        "12": {
          "epoch": 12,
          "step": 3540,
          "train_acc": 0.5593684022786831,
          "train_loss": 1.8862257361530823,
          "val_acc": 0.5626637554585153,
          "val_bleu": 0.12265383107576908,
          "val_levenshtein": 0.25617005543445687,
          "val_loss": 1.8589668412362375
        },
        "13": {
          "epoch": 13,
          "step": 3835,
          "train_acc": 0.5609239303561029,
          "train_loss": 1.877886815175627,
          "val_acc": 0.5686269259289775,
          "val_bleu": 0.12468451384044958,
          "val_levenshtein": 0.25848060280816154,
          "val_loss": 1.8335246444745446
        },
        "14": {
          "epoch": 14,
          "step": 4130,
          "train_acc": 0.562208252297093,
          "train_loss": 1.8695671484233611,
          "val_acc": 0.5702747795995715,
          "val_bleu": 0.1262939208419381,
          "val_levenshtein": 0.259631283232244,
          "val_loss": 1.828028661917045
        },
        "15": {
          "epoch": 15,
          "step": 4425,
          "train_acc": 0.563253545100891,
          "train_loss": 1.8636963321124544,
          "val_acc": 0.5722027683941666,
          "val_bleu": 0.12720227864314979,
          "val_levenshtein": 0.2604922744792089,
          "val_loss": 1.8224660227090796
        },
        "16": {
          "epoch": 16,
          "step": 4720,
          "train_acc": 0.5643404381679887,
          "train_loss": 1.8568403282311223,
          "val_acc": 0.5686825409903601,
          "val_bleu": 0.12705237153901847,
          "val_levenshtein": 0.2598162103837701,
          "val_loss": 1.8364158136442998
        },
        "17": {
          "epoch": 17,
          "step": 5015,
          "train_acc": 0.565547765146518,
          "train_loss": 1.8502415621442994,
          "val_acc": 0.5718217022328417,
          "val_bleu": 0.12680663527662278,
          "val_levenshtein": 0.25997951714358297,
          "val_loss": 1.815738298160913
        },
        "18": {
          "epoch": 18,
          "step": 5310,
          "train_acc": 0.5662165870592383,
          "train_loss": 1.8449508394255902,
          "val_acc": 0.5719391118068715,
          "val_bleu": 0.12857843144789807,
          "val_levenshtein": 0.2607249180743164,
          "val_loss": 1.8139267730598951
        },
        "19": {
          "epoch": 19,
          "step": 5605,
          "train_acc": 0.566649827370399,
          "train_loss": 1.8429248752438796,
          "val_acc": 0.5726106121776386,
          "val_bleu": 0.13067098074546907,
          "val_levenshtein": 0.26029159089873755,
          "val_loss": 1.8061173566638213
        },
        "2": {
          "epoch": 2,
          "step": 590,
          "train_acc": 0.4979027491568477,
          "train_loss": 2.286718433364924,
          "val_acc": 0.5172077119551783,
          "val_bleu": 0.09383304914745247,
          "val_levenshtein": 0.23528464560691537,
          "val_loss": 2.1587390434784703
        },
        "20": {
          "epoch": 20,
          "step": 5900,
          "train_acc": 0.5680088459167618,
          "train_loss": 1.8350824033394482,
          "val_acc": 0.5749649831094998,
          "val_bleu": 0.1319371533793485,
          "val_levenshtein": 0.26152056602726403,
          "val_loss": 1.7988670310096786
        },
        "21": {
          "epoch": 21,
          "step": 6195,
          "train_acc": 0.568066994351098,
          "train_loss": 1.8347688058094898,
          "val_acc": 0.5738320837109665,
          "val_bleu": 0.12945058851626895,
          "val_levenshtein": 0.2603022884709557,
          "val_loss": 1.8022915339384455
        },
        "22": {
          "epoch": 22,
          "step": 6490,
          "train_acc": 0.5694195774976132,
          "train_loss": 1.8275334371787217,
          "val_acc": 0.5744026530444096,
          "val_bleu": 0.128856994943602,
          "val_levenshtein": 0.26001403076116236,
          "val_loss": 1.8010593653864615
        },
        "23": {
          "epoch": 23,
          "step": 6785,
          "train_acc": 0.5699776185986732,
          "train_loss": 1.823231741342383,
          "val_acc": 0.5771957650160666,
          "val_bleu": 0.13003075372572886,
          "val_levenshtein": 0.26158316113752245,
          "val_loss": 1.7877880568430273
        },
        "24": {
          "epoch": 24,
          "step": 7080,
          "train_acc": 0.5706308116831926,
          "train_loss": 1.819682347319206,
          "val_acc": 0.576724066902859,
          "val_bleu": 0.13067928561223502,
          "val_levenshtein": 0.26130776185896615,
          "val_loss": 1.7881254489276572
        },
        "25": {
          "epoch": 25,
          "step": 7375,
          "train_acc": 0.5710904831008699,
          "train_loss": 1.8172984074817786,
          "val_acc": 0.577284337150861,
          "val_bleu": 0.1328433614135321,
          "val_levenshtein": 0.2618783256880025,
          "val_loss": 1.7821237397735121
        },
        "26": {
          "epoch": 26,
          "step": 7670,
          "train_acc": 0.5714947641127169,
          "train_loss": 1.814012570569619,
          "val_acc": 0.5783080662437176,
          "val_bleu": 0.13209127669424392,
          "val_levenshtein": 0.26212457483685225,
          "val_loss": 1.7816787483017078
        },
        "27": {
          "epoch": 27,
          "step": 7965,
          "train_acc": 0.5722587380088965,
          "train_loss": 1.8105782902403078,
          "val_acc": 0.5763821372662108,
          "val_bleu": 0.13274708992195544,
          "val_levenshtein": 0.26222128848513204,
          "val_loss": 1.7843558183850068
        },
        "3": {
          "epoch": 3,
          "step": 885,
          "train_acc": 0.5185247581323918,
          "train_loss": 2.1481244177614007,
          "val_acc": 0.5318921479772596,
          "val_bleu": 0.10239467894490184,
          "val_levenshtein": 0.24183516364747928,
          "val_loss": 2.0602857327090938
        },
        "4": {
          "epoch": 4,
          "step": 1180,
          "train_acc": 0.5308607301328864,
          "train_loss": 2.068824692352077,
          "val_acc": 0.5398677597429349,
          "val_bleu": 0.1074516537417477,
          "val_levenshtein": 0.2474383489959445,
          "val_loss": 2.0134648335592438
        },
        "5": {
          "epoch": 5,
          "step": 1475,
          "train_acc": 0.5384827717451012,
          "train_loss": 2.0191773430068247,
          "val_acc": 0.5478145340693746,
          "val_bleu": 0.11254703313028021,
          "val_levenshtein": 0.2496339736505115,
          "val_loss": 1.9652107989061691
        },
        "6": {
          "epoch": 6,
          "step": 1770,
          "train_acc": 0.5441001863048256,
          "train_loss": 1.9823869967816954,
          "val_acc": 0.553108263986158,
          "val_bleu": 0.11509794412769259,
          "val_levenshtein": 0.25140414518145604,
          "val_loss": 1.9319194194378961
        },
        "7": {
          "epoch": 7,
          "step": 2065,
          "train_acc": 0.5478285811736054,
          "train_loss": 1.9575183286828401,
          "val_acc": 0.5579076378017632,
          "val_bleu": 0.11645909279213411,
          "val_levenshtein": 0.25343742687892074,
          "val_loss": 1.905793549253949
        },
        "8": {
          "epoch": 8,
          "step": 2360,
          "train_acc": 0.5510621397612558,
          "train_loss": 1.9371488370534313,
          "val_acc": 0.5587047870149131,
          "val_bleu": 0.1202438752050283,
          "val_levenshtein": 0.2539664510364346,
          "val_loss": 1.8968321896510882
        },
        "9": {
          "epoch": 9,
          "step": 2655,
          "train_acc": 0.5539422110287124,
          "train_loss": 1.9202021786969432,
          "val_acc": 0.5612898574606575,
          "val_bleu": 0.12122708216070639,
          "val_levenshtein": 0.2557460489855524,
          "val_loss": 1.876403668675941
        }
      }
    },
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v3",
    "status": "training",
    "tags": [
      "resnet_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v4": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v4/config.yaml",
    "creation_time": "2025-04-16 23:05:06",
    "description": "Image-to-LaTeX model: resnet_lstm with 2048 embedding dim, 2048 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=30",
    "last_updated": "2025-04-16 23:05:06",
    "metrics": {},
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v4",
    "status": "training",
    "tags": [
      "resnet_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v5": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v5/config.yaml",
    "creation_time": "2025-04-16 23:05:47",
    "description": "Image-to-LaTeX model: resnet_lstm with 2048 embedding dim, 2048 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=30",
    "last_updated": "2025-04-16 23:05:47",
    "metrics": {},
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v5",
    "status": "training",
    "tags": [
      "resnet_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v6": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v6/config.yaml",
    "creation_time": "2025-04-16 23:01:45",
    "description": "Image-to-LaTeX model: resnet_lstm with 2048 embedding dim, 2048 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=30",
    "last_updated": "2025-04-16 23:01:45",
    "metrics": {},
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v6",
    "status": "training",
    "tags": [
      "resnet_lstm",
      "lr_0.001"
    ]
  },
  "img2latex_v7": {
    "config_path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v7/config.yaml",
    "creation_time": "2025-04-16 23:02:14",
    "description": "Image-to-LaTeX model: resnet_lstm with 2048 embedding dim, 2048 hidden dim. Training with lr=0.001, batch_size=128, max_epochs=30",
    "last_updated": "2025-04-16 23:02:14",
    "metrics": {},
    "path": "/Users/jeremy/hmer-im2latex/outputs/img2latex_v7",
    "status": "training",
    "tags": [
      "resnet_lstm",
      "lr_0.001"
    ]
  }
}